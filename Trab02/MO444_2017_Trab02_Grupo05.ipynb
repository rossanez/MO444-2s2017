{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MO444-A 2s/2017 - Second assignment\n",
    "#\n",
    "#         Group 05\n",
    "#\n",
    "# - Anderson Rossanez (124136)\n",
    "# - Bruno Branta Lopes (31470)\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "from scipy import misc\n",
    "import glob\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from skimage.io import imread\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some definitions\n",
    "classes = np.asarray(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "def load_image_dataset(name, n):\n",
    "    images = []\n",
    "    with open('cifar-10/%s/labels' % name) as labels:\n",
    "        i = 0\n",
    "        for path in sorted(glob.glob('cifar-10/%s/*.png' % name)):\n",
    "            # Reading the images as grayscale to have a 32x32 matrix,\n",
    "            # instead of a 32x32x3 matrix in case of RGB.\n",
    "            images.append((imread(path, as_grey=True), labels.next()))\n",
    "            i += 1\n",
    "            if i >= n:\n",
    "                break\n",
    "    return images\n",
    "\n",
    "def load_dataset(name):\n",
    "    dataset = load_image_dataset(name=name, n = 50000)\n",
    "    \n",
    "    data_X = [i[0] for i in dataset]\n",
    "    data_Y = [int(i[1]) for i in dataset]\n",
    "    \n",
    "    return np.array(data_X), np.array(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "data_X, data_Y = load_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmfJ/Lf1Jv4aGfSQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115057690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    }
   ],
   "source": [
    "# Take a look at a sample and its class (207 should be a cat [3])\n",
    "plt.imshow(data_X[207], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Label: %s' % data_Y[207])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (50000, 32, 32)\n",
      "Flattened shape: (50000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Flatten data to 1-D\n",
    "def flatten_data(data):\n",
    "    reshaped = data.reshape(-1, 32*32)\n",
    "    return reshaped\n",
    "\n",
    "print('Previous shape: {}'.format(data_X.shape))\n",
    "\n",
    "data_X = flatten_data(data_X)\n",
    "\n",
    "print('Flattened shape: {}'.format(data_X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementing K-Fold to help avoiding overfitting\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "# prepare for 5-fold execution\n",
    "k5_fold = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "def run_kfold(method, data_Y, data_X, scale=False, partial_fit=False):\n",
    "    train_precision, train_recall, train_f1 = [], [], []\n",
    "    validation_precision, validation_recall, validation_f1 = [], [], []\n",
    "    start_time = datetime.now()\n",
    "    k = 0\n",
    "    print('k', end=' ')\n",
    "    model = None\n",
    "    for train_index, validation_index in k5_fold.split(data_X):\n",
    "        k += 1\n",
    "        print(k, end=' ')\n",
    "        \n",
    "        train_data_X, train_data_Y = data_X[train_index], data_Y[train_index]\n",
    "        validation_data_X, validation_data_Y = data_X[validation_index], data_Y[validation_index]\n",
    "        \n",
    "        if scale:\n",
    "            model_scaler = preprocessing.StandardScaler()\n",
    "            train_data_X = model_scaler.fit_transform(train_data_X)\n",
    "            validation_data_X = model_scaler.transform(validation_data_X)\n",
    "        \n",
    "        if partial_fit:\n",
    "            # feed the data partially\n",
    "            n_chunks = 10\n",
    "            chunk_size = len(train_data_Y) / n_chunks\n",
    "            for i in range(0, n_chunks):\n",
    "                range_start = i * chunk_size\n",
    "                range_end = (i + 1) * chunk_size\n",
    "                model = method(train_data_X[range_start:range_end], train_data_Y[range_start:range_end]) \n",
    "        else:\n",
    "            model = method(train_data_X, train_data_Y)\n",
    "        \n",
    "        predicted_train_data_Y = model.predict(train_data_X)\n",
    "        train_precision.append(precision_score(train_data_Y, predicted_train_data_Y))\n",
    "        train_recall.append(recall_score(train_data_Y, predicted_train_data_Y))\n",
    "        train_f1.append(f1_score(train_data_Y, predicted_train_data_Y))\n",
    "        \n",
    "        predicted_validation_data_Y = model.predict(validation_data_X)\n",
    "        validation_precision.append(precision_score(validation_data_Y, predicted_validation_data_Y))\n",
    "        validation_recall.append(recall_score(validation_data_Y, predicted_validation_data_Y))\n",
    "        validation_f1.append(f1_score(validation_data_Y, predicted_validation_data_Y))\n",
    "    print('time elapsed: {}\\n'.format(datetime.now() - start_time))\n",
    "    print('             Precision  Recall  F1 Score')\n",
    "    print('Training:      %5.2f    %5.2f   %5.2f' % (np.mean(train_precision), np.mean(train_recall), np.mean(train_f1)))\n",
    "    print('Validation:    %5.2f    %5.2f   %5.2f' % (np.mean(validation_precision), np.mean(validation_recall), np.mean(validation_f1)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (OVA) model 1/10\n",
      "k 1 2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Library/Python/2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 time elapsed: 0:00:04.404142\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.25      0.11    0.09\n",
      "Validation:     0.21      0.09    0.08\n",
      "Logistic Regression (OVA) model 2/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.528377\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.50      0.22    0.29\n",
      "Validation:     0.44      0.20    0.26\n",
      "Logistic Regression (OVA) model 3/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.243258\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.20      0.13    0.09\n",
      "Validation:     0.11      0.12    0.09\n",
      "Logistic Regression (OVA) model 4/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.237693\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.32      0.07    0.08\n",
      "Validation:     0.27      0.06    0.07\n",
      "Logistic Regression (OVA) model 5/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.575314\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.24      0.10    0.06\n",
      "Validation:     0.25      0.10    0.06\n",
      "Logistic Regression (OVA) model 6/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.503154\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.33      0.20    0.14\n",
      "Validation:     0.29      0.19    0.13\n",
      "Logistic Regression (OVA) model 7/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.359251\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.21      0.19    0.15\n",
      "Validation:     0.17      0.15    0.12\n",
      "Logistic Regression (OVA) model 8/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.482624\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.55      0.21    0.09\n",
      "Validation:     0.27      0.20    0.09\n",
      "Logistic Regression (OVA) model 9/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.539377\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.28      0.28    0.14\n",
      "Validation:     0.21      0.28    0.13\n",
      "Logistic Regression (OVA) model 10/10\n",
      "k 1 2 3 4 5 time elapsed: 0:00:04.835172\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.34      0.43    0.24\n",
      "Validation:     0.27      0.41    0.23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False),\n",
       " SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "        eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "        learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
       "        penalty='l2', power_t=0.5,\n",
       "        random_state=<mtrand.RandomState object at 0x1149d8be0>,\n",
       "        shuffle=True, verbose=0, warm_start=False)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a baseline One-vs-All logistic regression model\n",
    "\n",
    "def one_vs_all(data_X, data_Y, num_classes):\n",
    "    classifiers = []\n",
    "    for i in range(num_classes):\n",
    "        # 1 for this class, 0 for all the others\n",
    "        data_Y_i = np.array([1 if j == i else 0 for j in data_Y])\n",
    "        \n",
    "        print('Logistic Regression (OVA) model %d/%d' % (i+1, num_classes))\n",
    "        \n",
    "        # train and run using k-fold to help avoid overfitting \n",
    "        this_model = run_kfold(lambda X, Y: SGDClassifier(loss='log', random_state=random_state).fit(X, Y), data_Y_i, data_X)\n",
    "        classifiers.append(this_model)\n",
    "    \n",
    "    return classifiers\n",
    "\n",
    "# Train, run, and measure\n",
    "one_vs_all(data_X, data_Y, len(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
