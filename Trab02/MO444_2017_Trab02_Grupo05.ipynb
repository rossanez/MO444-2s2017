{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MO444-A 2s/2017 - Second assignment\n",
    "#\n",
    "#         Group 05\n",
    "#\n",
    "# - Anderson Rossanez (124136)\n",
    "# - Bruno Branta Lopes (31470)\n",
    "#\n",
    "\n",
    "from __future__ import print_function\n",
    "import glob\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "from skimage.io import imread\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "# Some definitions\n",
    "classes = np.asarray(['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'])\n",
    "\n",
    "def load_image_dataset(name, n=None):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open('cifar-10/%s/labels' % name) as labels:\n",
    "        i = 0\n",
    "        for path in sorted(glob.glob('cifar-10/%s/*.png' % name)):\n",
    "            # Reading the images as grayscale to have a 32x32 matrix,\n",
    "            # instead of a 32x32x3 matrix in case of RGB.\n",
    "            X.append(imread(path, as_grey=True))\n",
    "            Y.append(int(labels.next()))\n",
    "            i += 1\n",
    "            if n != None and i >= n:\n",
    "                break\n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "data_X, data_Y = load_image_dataset('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take a look at a sample and its class (207 should be a cat [3])\n",
    "plt.imshow(data_X[207], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "print('Label: %s' % data_Y[207])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: (50000, 32, 32)\n",
      "Flattened shape: (50000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# Flatten data to 1-D\n",
    "def flatten_data(data):\n",
    "    print('Previous shape: {}'.format(data.shape))\n",
    "    reshaped = data.reshape(-1, 32*32)\n",
    "    print('Flattened shape: {}'.format(reshaped.shape))\n",
    "    return reshaped\n",
    "\n",
    "data_X = flatten_data(data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementing K-Fold to help avoiding overfitting\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "\n",
    "random_state = np.random.RandomState(1)\n",
    "\n",
    "# prepare for 5-fold execution\n",
    "k5_fold = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "def run_kfold(method, data_Y, data_X, scale=False):\n",
    "    train_precision, train_recall, train_f1 = [], [], []\n",
    "    validation_precision, validation_recall, validation_f1 = [], [], []\n",
    "    start_time = datetime.now()\n",
    "    k = 0\n",
    "    print('k', end=' ')\n",
    "    model = None\n",
    "\n",
    "    for train_index, validation_index in k5_fold.split(data_X):\n",
    "        k += 1\n",
    "        print(k, end=' ')\n",
    "        \n",
    "        train_data_X, train_data_Y = data_X[train_index], data_Y[train_index]\n",
    "        validation_data_X, validation_data_Y = data_X[validation_index], data_Y[validation_index]\n",
    "        \n",
    "        if scale:\n",
    "            model_scaler = preprocessing.StandardScaler()\n",
    "            train_data_X = model_scaler.fit_transform(train_data_X)\n",
    "            validation_data_X = model_scaler.transform(validation_data_X)\n",
    "\n",
    "        # Train the model(s) using the training data\n",
    "        model = method(train_data_X, train_data_Y)\n",
    "        \n",
    "        # Predict training data\n",
    "        predicted_train_data_Y = model.predict(train_data_X)\n",
    "        train_precision.append(precision_score(train_data_Y, predicted_train_data_Y, average='weighted'))\n",
    "        train_recall.append(recall_score(train_data_Y, predicted_train_data_Y, average='weighted'))\n",
    "        train_f1.append(f1_score(train_data_Y, predicted_train_data_Y, average='weighted'))\n",
    "        \n",
    "        # Predict validation data\n",
    "        predicted_validation_data_Y = model.predict(validation_data_X)\n",
    "        validation_precision.append(precision_score(validation_data_Y, predicted_validation_data_Y, average='weighted'))\n",
    "        validation_recall.append(recall_score(validation_data_Y, predicted_validation_data_Y, average='weighted'))\n",
    "        validation_f1.append(f1_score(validation_data_Y, predicted_validation_data_Y, average='weighted'))\n",
    "    \n",
    "    print('time elapsed: {}\\n'.format(datetime.now() - start_time))\n",
    "    print('             Precision  Recall  F1 Score')\n",
    "    print('Training:      %5.2f    %5.2f   %5.2f' % (np.mean(train_precision), np.mean(train_recall), np.mean(train_f1)))\n",
    "    print('Validation:    %5.2f    %5.2f   %5.2f' % (np.mean(validation_precision), np.mean(validation_recall), np.mean(validation_f1)))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 1 2 3 4 5 time elapsed: 0:08:18.840899\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.34     0.35    0.34\n",
      "Validation:     0.27     0.27    0.27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a baseline One-vs-All logistic regression model\n",
    "ova_lr_model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=100)\n",
    "run_kfold(lambda X, Y: ova_lr_model.fit(X, Y), data_Y, data_X, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k 1 2 3 4 5 time elapsed: 0:06:28.648144\n",
      "\n",
      "             Precision  Recall  F1 Score\n",
      "Training:       0.34     0.34    0.34\n",
      "Validation:     0.27     0.28    0.27\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Multinomial logistic regression model\n",
    "mn_lr_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=100)\n",
    "run_kfold(lambda X, Y: mn_lr_model.fit(X, Y), data_Y, data_X, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Networks\n",
    "class NeuralNetwork(object):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, learning_rate=0.5, epochs=10, batch_size=100):\n",
    "        self.learning_rate=learning_rate\n",
    "        self.epochs=epochs\n",
    "        self.batch_size=batch_size\n",
    "        \n",
    "        # Setup one hot encoder.\n",
    "        self.encoder = preprocessing.OneHotEncoder()\n",
    "        \n",
    "        # input data placeholders\n",
    "        self.x = tf.placeholder(tf.float32, [None, input_size])\n",
    "        # output data placeholder - 10 digits\n",
    "        self.y = tf.placeholder(tf.float32, [None, output_size])\n",
    "\n",
    "        # now declare the weights connecting the input to the hidden layer\n",
    "        self.W1 = tf.Variable(tf.random_normal([input_size, 300], stddev=0.03), name='W1')\n",
    "        self.b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
    "\n",
    "        # and the weights connecting the hidden layer to the output layer\n",
    "        self.W2 = tf.Variable(tf.random_normal([300, output_size], stddev=0.03), name='W2')\n",
    "        self.b2 = tf.Variable(tf.random_normal([output_size]), name='b2')\n",
    "        \n",
    "        # calculate the hidden layer's output\n",
    "        Z = tf.add(tf.matmul(self.x, self.W1), self.b1)\n",
    "        self.hidden_out = tf.nn.relu(Z)\n",
    "        \n",
    "        # now calculate the hidden layer output - in this case, let's use a softmax activated\n",
    "        # output layer\n",
    "        self.y_ = tf.nn.softmax(tf.add(tf.matmul(self.hidden_out, self.W2), self.b2))\n",
    "        \n",
    "        y_clipped = tf.clip_by_value(self.y_, 1e-10, 0.9999999)\n",
    "        cross_entropy = -tf.reduce_mean(tf.reduce_sum(self.y * tf.log(y_clipped) + (1 - self.y) * tf.log(1 - y_clipped), axis=1))\n",
    "        # add an optimizer\n",
    "        self.optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "        \n",
    "        # finally setup the initialisation operator\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        \n",
    "        # define an accuracy assessment operation\n",
    "        correct_prediction = tf.equal(tf.argmax(self.y, 1), tf.argmax(self.y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "    def fit(self, data_X, data_Y):\n",
    "        encoder.fit(data_Y)\n",
    "        \n",
    "        data_Y_enc = encoder.transform(data_Y).toarray()\n",
    "        \n",
    "        # start the session\n",
    "        with tf.Session() as sess:\n",
    "            # initialize the variables\n",
    "            sess.run(self.init_op)\n",
    "            \n",
    "            for epoch in range(epochs):              \n",
    "                _, c = sess.run([optimizer, cross_entropy], feed_dict={x: data_X, y: data_y})\n",
    "                print(\"Epoch:\", (epoch + 1))\n",
    "            print(sess.run(accuracy, feed_dict={x: data_X, y: data_y}))\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network with a single hidden layer\n",
    "nn_single_hl = NeuralNetwork(input_size=len(data_X[0]), output_size=len(classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
