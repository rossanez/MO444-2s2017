{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MO444 2s/2017 - First assignment\n",
    "#\n",
    "#         Group 05\n",
    "#\n",
    "# - Anderson Rossanez (124136)\n",
    "# - Bruno Branta Lopes (31470)\n",
    "#\n",
    "\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Functions\n",
    "def load_data(filename):\n",
    "    raw_data = open(filename, 'rt')\n",
    "    data = np.loadtxt(raw_data, delimiter=\",\")\n",
    "    return data\n",
    "\n",
    "def split_Y_X(dataset):\n",
    "    Y = dataset[:,0]\n",
    "    X = dataset[:,1:]\n",
    "    return Y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 463715\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "data = load_data('year-prediction-msd-train.txt')\n",
    "\n",
    "print('Training data size: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>46.50128</td>\n",
       "      <td>-18.37096</td>\n",
       "      <td>58.89824</td>\n",
       "      <td>27.28181</td>\n",
       "      <td>1.93097</td>\n",
       "      <td>-2.43167</td>\n",
       "      <td>18.64843</td>\n",
       "      <td>-5.62769</td>\n",
       "      <td>-1.47711</td>\n",
       "      <td>...</td>\n",
       "      <td>43.94716</td>\n",
       "      <td>-64.21148</td>\n",
       "      <td>13.04284</td>\n",
       "      <td>156.03785</td>\n",
       "      <td>-2.42670</td>\n",
       "      <td>51.71977</td>\n",
       "      <td>-43.56703</td>\n",
       "      <td>10.63735</td>\n",
       "      <td>24.08962</td>\n",
       "      <td>-21.41886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>41.46015</td>\n",
       "      <td>-52.30140</td>\n",
       "      <td>-4.59825</td>\n",
       "      <td>-19.28084</td>\n",
       "      <td>-11.85844</td>\n",
       "      <td>-19.54192</td>\n",
       "      <td>1.30306</td>\n",
       "      <td>-1.83185</td>\n",
       "      <td>5.98469</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.48435</td>\n",
       "      <td>-154.65715</td>\n",
       "      <td>35.22429</td>\n",
       "      <td>89.53649</td>\n",
       "      <td>-3.13145</td>\n",
       "      <td>-128.28120</td>\n",
       "      <td>89.97277</td>\n",
       "      <td>-15.88139</td>\n",
       "      <td>-75.21074</td>\n",
       "      <td>-0.51139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>42.18667</td>\n",
       "      <td>-85.65863</td>\n",
       "      <td>-7.91506</td>\n",
       "      <td>-11.84193</td>\n",
       "      <td>-12.61959</td>\n",
       "      <td>-21.66749</td>\n",
       "      <td>4.97883</td>\n",
       "      <td>-11.86750</td>\n",
       "      <td>9.87342</td>\n",
       "      <td>...</td>\n",
       "      <td>42.08584</td>\n",
       "      <td>-181.77349</td>\n",
       "      <td>43.00181</td>\n",
       "      <td>87.94977</td>\n",
       "      <td>-13.70362</td>\n",
       "      <td>136.49979</td>\n",
       "      <td>140.32633</td>\n",
       "      <td>11.51422</td>\n",
       "      <td>382.79589</td>\n",
       "      <td>29.98269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>46.90244</td>\n",
       "      <td>19.86314</td>\n",
       "      <td>10.92119</td>\n",
       "      <td>4.87136</td>\n",
       "      <td>-41.17499</td>\n",
       "      <td>-19.84156</td>\n",
       "      <td>2.93308</td>\n",
       "      <td>-5.98711</td>\n",
       "      <td>3.05997</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.76407</td>\n",
       "      <td>-20.31782</td>\n",
       "      <td>-75.24506</td>\n",
       "      <td>125.81801</td>\n",
       "      <td>-15.50828</td>\n",
       "      <td>-63.31002</td>\n",
       "      <td>-142.21937</td>\n",
       "      <td>-12.36699</td>\n",
       "      <td>32.45911</td>\n",
       "      <td>-17.14909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>46.64388</td>\n",
       "      <td>-81.99503</td>\n",
       "      <td>41.62851</td>\n",
       "      <td>3.65855</td>\n",
       "      <td>-9.38201</td>\n",
       "      <td>-13.51749</td>\n",
       "      <td>7.48781</td>\n",
       "      <td>-7.03302</td>\n",
       "      <td>7.06982</td>\n",
       "      <td>...</td>\n",
       "      <td>12.29244</td>\n",
       "      <td>-143.25348</td>\n",
       "      <td>91.15842</td>\n",
       "      <td>-227.85481</td>\n",
       "      <td>7.75916</td>\n",
       "      <td>-41.32376</td>\n",
       "      <td>-225.66526</td>\n",
       "      <td>-4.05081</td>\n",
       "      <td>455.39458</td>\n",
       "      <td>41.65310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0  2004  46.50128 -18.37096  58.89824  27.28181   1.93097  -2.43167  18.64843   \n",
       "1  2005  41.46015 -52.30140  -4.59825 -19.28084 -11.85844 -19.54192   1.30306   \n",
       "2  2009  42.18667 -85.65863  -7.91506 -11.84193 -12.61959 -21.66749   4.97883   \n",
       "3  1987  46.90244  19.86314  10.92119   4.87136 -41.17499 -19.84156   2.93308   \n",
       "4  2009  46.64388 -81.99503  41.62851   3.65855  -9.38201 -13.51749   7.48781   \n",
       "\n",
       "         8        9     ...           81         82        83         84  \\\n",
       "0  -5.62769 -1.47711    ...     43.94716  -64.21148  13.04284  156.03785   \n",
       "1  -1.83185  5.98469    ...    -13.48435 -154.65715  35.22429   89.53649   \n",
       "2 -11.86750  9.87342    ...     42.08584 -181.77349  43.00181   87.94977   \n",
       "3  -5.98711  3.05997    ...     -2.76407  -20.31782 -75.24506  125.81801   \n",
       "4  -7.03302  7.06982    ...     12.29244 -143.25348  91.15842 -227.85481   \n",
       "\n",
       "         85         86         87        88         89        90  \n",
       "0  -2.42670   51.71977  -43.56703  10.63735   24.08962 -21.41886  \n",
       "1  -3.13145 -128.28120   89.97277 -15.88139  -75.21074  -0.51139  \n",
       "2 -13.70362  136.49979  140.32633  11.51422  382.79589  29.98269  \n",
       "3 -15.50828  -63.31002 -142.21937 -12.36699   32.45911 -17.14909  \n",
       "4   7.75916  -41.32376 -225.66526  -4.05081  455.39458  41.65310  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the data (5 first instances):\n",
    "# - first column (index 0) is the song release year\n",
    "# - remaining columns are the the features (indexes 1 - 90)\n",
    "data_frame = pd.DataFrame(data)\n",
    "data_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 370972\n",
      "Validation data size: 92743\n"
     ]
    }
   ],
   "source": [
    "# split train data into training/validation (80/20)\n",
    "train_data, validation_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "print('Train data size: {}'.format(len(train_data)))\n",
    "print('Validation data size: {}'.format(len(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size: 36285\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test_data = load_data('year-prediction-msd-test.txt')\n",
    "\n",
    "print('Test data size: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split label (years) and features\n",
    "train_data_Y, train_data_X = split_Y_X(train_data)\n",
    "validation_data_Y, validation_data_X = split_Y_X(validation_data)\n",
    "test_data_Y, test_data_X = split_Y_X(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coefficients: 90\n",
      "Coefficients: [  8.68591059e-01  -5.52453290e-02  -4.32916275e-02   4.39407673e-03\n",
      "  -1.46660719e-02  -2.24614732e-01  -5.84525370e-03  -1.02024786e-01\n",
      "  -6.75868065e-02   2.12701171e-02  -1.63706481e-01  -2.79243840e-03\n",
      "   4.64957381e-02   3.48450325e-04  -4.48324966e-04   6.17709989e-04\n",
      "   4.64360139e-04   1.43235634e-03   1.90838121e-03   2.22886368e-03\n",
      "   8.69399293e-04  -3.68153515e-04   7.65460560e-03   2.74044092e-03\n",
      "  -3.48903791e-03   3.38553374e-05   1.64915922e-03   3.92765972e-04\n",
      "   8.52336286e-04  -2.30430161e-04  -1.31670155e-03  -1.28190971e-03\n",
      "  -5.37198135e-03   2.92529890e-03   1.52136546e-03  -5.03030283e-03\n",
      "  -2.61238854e-04   6.56544337e-04   1.41131962e-03  -1.70044205e-03\n",
      "  -2.07641088e-03  -7.51878989e-04  -1.84886458e-03  -2.25075619e-03\n",
      "  -3.56185013e-03   6.56805141e-03   4.92561105e-04  -2.08340504e-03\n",
      "   3.43746644e-04   2.00553595e-03   1.09991493e-04  -1.80842616e-03\n",
      "   1.96854185e-03   9.30442562e-05  -2.02256596e-04   2.22396269e-04\n",
      "  -1.97739266e-03   1.89655866e-03  -1.27027693e-03   4.23374422e-04\n",
      "  -2.64596708e-03  -1.91931217e-03  -8.16515106e-03   1.20954192e-03\n",
      "  -2.01725686e-03   7.39395463e-04  -2.60745427e-05  -5.03696403e-04\n",
      "  -4.17543498e-03  -5.32143086e-03  -1.02145159e-03   3.45562193e-04\n",
      "   6.80961878e-04   4.46944408e-03   2.72408237e-03   1.49577651e-02\n",
      "   1.95159009e-04  -4.42863678e-03  -3.25425999e-05  -1.40996426e-04\n",
      "  -5.96973112e-04  -5.60394241e-04   1.27410970e-03   9.92060068e-04\n",
      "   2.67692251e-02   5.96434518e-05   1.22910070e-03  -3.12039221e-02\n",
      "  -1.34362484e-03  -9.04307983e-04]\n"
     ]
    }
   ],
   "source": [
    "# Create a baseline linear regression model and train it\n",
    "lr_base_model = LinearRegression()\n",
    "lr_base_model.fit(train_data_X, train_data_Y)\n",
    "\n",
    "print('Number of coefficients: {}'.format(len(lr_base_model.coef_)))\n",
    "print('Coefficients: {}'.format(lr_base_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [ 2005.  2007.  2006.  2004.  2009.]\n",
      "Predicted: [ 2001.45930425  2001.42397006  1999.06194958  1996.28507524  2003.24200105]\n"
     ]
    }
   ],
   "source": [
    "# A quick comparison on some instances of the validation data with the predicted values...\n",
    "print('Actual: {}'.format(validation_data_Y[0:5]))\n",
    "print('Predicted: {}'.format(lr_base_model.predict(validation_data_X)[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error: 91.2938005026\n",
      "Training root mean squared error: 9.55477893531\n",
      "Validation mean squared error: 91.136899741\n",
      "Validation root mean squared error: 9.54656481364\n"
     ]
    }
   ],
   "source": [
    "# ... and the errors\n",
    "mean_sq_error_training = mean_squared_error(train_data_Y, lr_base_model.predict(train_data_X))\n",
    "print('Training mean squared error: {}'.format(mean_sq_error_training))\n",
    "print('Training root mean squared error: {}'.format(sqrt(mean_sq_error_training)))\n",
    "\n",
    "mean_sq_error_validation = mean_squared_error(validation_data_Y, lr_base_model.predict(validation_data_X))\n",
    "print('Validation mean squared error: {}'.format(mean_sq_error_validation))\n",
    "print('Validation root mean squared error: {}'.format(sqrt(mean_sq_error_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR-based alternative #1: Data normalization\n",
    "lr_normalized_model = LinearRegression(fit_intercept=True, normalize=True)\n",
    "\n",
    "lr_normalized_model.fit(train_data_X, train_data_Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training mean squared error: 91.2938005026\n",
      "Training root mean squared error: 9.55477893531\n",
      "Validation mean squared error: 91.136899741\n",
      "Validation root mean squared error: 9.54656481364\n"
     ]
    }
   ],
   "source": [
    "# Check the model errors\n",
    "mean_sq_error_training = mean_squared_error(train_data_Y, lr_normalized_model.predict(train_data_X))\n",
    "print('Training mean squared error: {}'.format(mean_sq_error_training))\n",
    "print('Training root mean squared error: {}'.format(sqrt(mean_sq_error_training)))\n",
    "\n",
    "mean_sq_error_validation = mean_squared_error(validation_data_Y, lr_normalized_model.predict(validation_data_X))\n",
    "print('Validation mean squared error: {}'.format(mean_sq_error_validation))\n",
    "print('Validation root mean squared error: {}'.format(sqrt(mean_sq_error_validation)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
