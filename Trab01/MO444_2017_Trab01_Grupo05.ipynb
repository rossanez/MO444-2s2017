{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MO444 2s/2017 - First assignment\n",
    "#\n",
    "#         Group 05\n",
    "#\n",
    "# - Anderson Rossanez (124136)\n",
    "# - Bruno Branta Lopes (31470)\n",
    "#\n",
    "\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Functions\n",
    "def load_data(filename):\n",
    "    raw_data = open(filename, 'rt')\n",
    "    data = np.loadtxt(raw_data, delimiter=\",\")\n",
    "    return data\n",
    "\n",
    "def split_Y_X(dataset):\n",
    "    Y = dataset[:,0]\n",
    "    X = dataset[:,1:]\n",
    "    return Y, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 463715\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "data = load_data('year-prediction-msd-train.txt')\n",
    "\n",
    "print('Training data size: {}'.format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>46.50128</td>\n",
       "      <td>-18.37096</td>\n",
       "      <td>58.89824</td>\n",
       "      <td>27.28181</td>\n",
       "      <td>1.93097</td>\n",
       "      <td>-2.43167</td>\n",
       "      <td>18.64843</td>\n",
       "      <td>-5.62769</td>\n",
       "      <td>-1.47711</td>\n",
       "      <td>...</td>\n",
       "      <td>43.94716</td>\n",
       "      <td>-64.21148</td>\n",
       "      <td>13.04284</td>\n",
       "      <td>156.03785</td>\n",
       "      <td>-2.42670</td>\n",
       "      <td>51.71977</td>\n",
       "      <td>-43.56703</td>\n",
       "      <td>10.63735</td>\n",
       "      <td>24.08962</td>\n",
       "      <td>-21.41886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>41.46015</td>\n",
       "      <td>-52.30140</td>\n",
       "      <td>-4.59825</td>\n",
       "      <td>-19.28084</td>\n",
       "      <td>-11.85844</td>\n",
       "      <td>-19.54192</td>\n",
       "      <td>1.30306</td>\n",
       "      <td>-1.83185</td>\n",
       "      <td>5.98469</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.48435</td>\n",
       "      <td>-154.65715</td>\n",
       "      <td>35.22429</td>\n",
       "      <td>89.53649</td>\n",
       "      <td>-3.13145</td>\n",
       "      <td>-128.28120</td>\n",
       "      <td>89.97277</td>\n",
       "      <td>-15.88139</td>\n",
       "      <td>-75.21074</td>\n",
       "      <td>-0.51139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>42.18667</td>\n",
       "      <td>-85.65863</td>\n",
       "      <td>-7.91506</td>\n",
       "      <td>-11.84193</td>\n",
       "      <td>-12.61959</td>\n",
       "      <td>-21.66749</td>\n",
       "      <td>4.97883</td>\n",
       "      <td>-11.86750</td>\n",
       "      <td>9.87342</td>\n",
       "      <td>...</td>\n",
       "      <td>42.08584</td>\n",
       "      <td>-181.77349</td>\n",
       "      <td>43.00181</td>\n",
       "      <td>87.94977</td>\n",
       "      <td>-13.70362</td>\n",
       "      <td>136.49979</td>\n",
       "      <td>140.32633</td>\n",
       "      <td>11.51422</td>\n",
       "      <td>382.79589</td>\n",
       "      <td>29.98269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>46.90244</td>\n",
       "      <td>19.86314</td>\n",
       "      <td>10.92119</td>\n",
       "      <td>4.87136</td>\n",
       "      <td>-41.17499</td>\n",
       "      <td>-19.84156</td>\n",
       "      <td>2.93308</td>\n",
       "      <td>-5.98711</td>\n",
       "      <td>3.05997</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.76407</td>\n",
       "      <td>-20.31782</td>\n",
       "      <td>-75.24506</td>\n",
       "      <td>125.81801</td>\n",
       "      <td>-15.50828</td>\n",
       "      <td>-63.31002</td>\n",
       "      <td>-142.21937</td>\n",
       "      <td>-12.36699</td>\n",
       "      <td>32.45911</td>\n",
       "      <td>-17.14909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>46.64388</td>\n",
       "      <td>-81.99503</td>\n",
       "      <td>41.62851</td>\n",
       "      <td>3.65855</td>\n",
       "      <td>-9.38201</td>\n",
       "      <td>-13.51749</td>\n",
       "      <td>7.48781</td>\n",
       "      <td>-7.03302</td>\n",
       "      <td>7.06982</td>\n",
       "      <td>...</td>\n",
       "      <td>12.29244</td>\n",
       "      <td>-143.25348</td>\n",
       "      <td>91.15842</td>\n",
       "      <td>-227.85481</td>\n",
       "      <td>7.75916</td>\n",
       "      <td>-41.32376</td>\n",
       "      <td>-225.66526</td>\n",
       "      <td>-4.05081</td>\n",
       "      <td>455.39458</td>\n",
       "      <td>41.65310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6         7   \\\n",
       "0  2004  46.50128 -18.37096  58.89824  27.28181   1.93097  -2.43167  18.64843   \n",
       "1  2005  41.46015 -52.30140  -4.59825 -19.28084 -11.85844 -19.54192   1.30306   \n",
       "2  2009  42.18667 -85.65863  -7.91506 -11.84193 -12.61959 -21.66749   4.97883   \n",
       "3  1987  46.90244  19.86314  10.92119   4.87136 -41.17499 -19.84156   2.93308   \n",
       "4  2009  46.64388 -81.99503  41.62851   3.65855  -9.38201 -13.51749   7.48781   \n",
       "\n",
       "         8        9     ...           81         82        83         84  \\\n",
       "0  -5.62769 -1.47711    ...     43.94716  -64.21148  13.04284  156.03785   \n",
       "1  -1.83185  5.98469    ...    -13.48435 -154.65715  35.22429   89.53649   \n",
       "2 -11.86750  9.87342    ...     42.08584 -181.77349  43.00181   87.94977   \n",
       "3  -5.98711  3.05997    ...     -2.76407  -20.31782 -75.24506  125.81801   \n",
       "4  -7.03302  7.06982    ...     12.29244 -143.25348  91.15842 -227.85481   \n",
       "\n",
       "         85         86         87        88         89        90  \n",
       "0  -2.42670   51.71977  -43.56703  10.63735   24.08962 -21.41886  \n",
       "1  -3.13145 -128.28120   89.97277 -15.88139  -75.21074  -0.51139  \n",
       "2 -13.70362  136.49979  140.32633  11.51422  382.79589  29.98269  \n",
       "3 -15.50828  -63.31002 -142.21937 -12.36699   32.45911 -17.14909  \n",
       "4   7.75916  -41.32376 -225.66526  -4.05081  455.39458  41.65310  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the data (5 first instances):\n",
    "# - first column (index 0) is the song release year\n",
    "# - remaining columns are the the features (indexes 1 - 90)\n",
    "data_frame = pd.DataFrame(data)\n",
    "data_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 370972\n",
      "Validation data size: 92743\n"
     ]
    }
   ],
   "source": [
    "# split train data into training/validation (80/20)\n",
    "train_data, validation_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "print('Train data size: {}'.format(len(train_data)))\n",
    "print('Validation data size: {}'.format(len(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size: 36285\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test_data = load_data('year-prediction-msd-test.txt')\n",
    "\n",
    "print('Test data size: {}'.format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split label (years) and features\n",
    "train_data_Y, train_data_X = split_Y_X(train_data)\n",
    "validation_data_Y, validation_data_X = split_Y_X(validation_data)\n",
    "test_data_Y, test_data_X = split_Y_X(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coefficients: 90\n",
      "Coefficients: [  8.69173858e-01  -5.57296220e-02  -4.36559430e-02   4.52886772e-03\n",
      "  -1.50833969e-02  -2.19801946e-01  -5.61995222e-03  -9.97464049e-02\n",
      "  -6.83511618e-02   2.41968169e-02  -1.68286781e-01  -2.30332728e-03\n",
      "   4.82442134e-02   3.51301142e-04  -4.31797823e-04   6.13460795e-04\n",
      "   4.29723747e-04   1.39298428e-03   1.99278197e-03   2.16509995e-03\n",
      "   6.97093760e-04  -4.73229057e-04   7.61441798e-03   2.56612448e-03\n",
      "  -3.60206692e-03   3.41194493e-05   1.62588512e-03   4.03100997e-04\n",
      "   9.00942807e-04  -2.15254470e-04  -1.20194456e-03  -1.47238318e-03\n",
      "  -5.62595703e-03   2.53637807e-03   1.93672497e-03  -5.16795969e-03\n",
      "  -2.49886475e-04   6.74450770e-04   1.47398952e-03  -1.77690581e-03\n",
      "  -1.96442504e-03  -7.92792336e-04  -1.33163673e-03  -1.95691027e-03\n",
      "  -3.22577161e-03   6.48437263e-03   4.59190380e-04  -2.01136901e-03\n",
      "   2.19206721e-04   2.04229284e-03   2.29082764e-04  -1.90719584e-03\n",
      "   1.94414419e-03  -1.25604309e-04  -2.79413664e-04   1.96066539e-04\n",
      "  -1.90651504e-03   1.87311112e-03  -1.21337758e-03   1.61300920e-04\n",
      "  -2.74234253e-03  -1.74430544e-03  -8.24448596e-03   1.18434628e-03\n",
      "  -2.02890644e-03   6.99984521e-04   1.88484049e-05  -5.04890558e-04\n",
      "  -4.22515729e-03  -5.24883749e-03  -1.13679101e-03   3.49736647e-04\n",
      "   7.24526681e-04   4.32787983e-03   2.96613998e-03   1.57708878e-02\n",
      "   1.71343010e-04  -4.51316264e-03  -1.45437136e-04  -7.78639184e-05\n",
      "  -9.66482956e-04  -5.87503096e-04   1.18966300e-03   8.72497690e-04\n",
      "   2.81040804e-02   1.24423233e-04   1.24520909e-03  -3.22004735e-02\n",
      "  -1.39756435e-03  -5.03344709e-04]\n"
     ]
    }
   ],
   "source": [
    "# Create a baseline linear regression model and train it\n",
    "lr_base_model = LinearRegression()\n",
    "lr_base_model.fit(train_data_X, train_data_Y)\n",
    "\n",
    "print('Number of coefficients: {}'.format(len(lr_base_model.coef_)))\n",
    "print('Coefficients: {}'.format(lr_base_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [ 2008.  2006.  1995.  2001.  2005.]\n",
      "Predicted: [ 2007.21805379  2001.86583498  1988.19555054  2004.03527608  1998.036657  ]\n",
      "Mean squared error: 91.4544261522\n",
      "Root mean squared error: 9.56318075497\n"
     ]
    }
   ],
   "source": [
    "# A quick comparison on some instances of the validation data with the predicted values...\n",
    "print('Actual: {}'.format(validation_data_Y[0:5]))\n",
    "print('Predicted: {}'.format(lr_base_model.predict(validation_data_X)[0:5]))\n",
    "\n",
    "# ... and the errors\n",
    "mean_sq_error = mean_squared_error(validation_data_Y, lr_base_model.predict(validation_data_X))\n",
    "print('Mean squared error: {}'.format(mean_sq_error))\n",
    "print('Root mean squared error: {}'.format(sqrt(mean_sq_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LR-based alternative #1: Data normalization\n",
    "lr_normalized_model = LinearRegression(fit_intercept=True, normalize=True)\n",
    "\n",
    "lr_normalized_model.fit(train_data_X, train_data_Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 91.4544261522\n",
      "Root mean squared error: 9.56318075497\n"
     ]
    }
   ],
   "source": [
    "# Check the model errors\n",
    "mean_sq_error = mean_squared_error(validation_data_Y, lr_normalized_model.predict(validation_data_X))\n",
    "print('Mean squared error: {}'.format(mean_sq_error))\n",
    "print('Root mean squared error: {}'.format(sqrt(mean_sq_error)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
